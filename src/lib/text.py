import re

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if casefold:
        text = text.casefold()
    if yo2e:
        text = text.replace('Ð','Ð•').replace('Ñ‘','Ðµ')
    text = text.replace('\n',' ').replace('\t',' ').replace('\r',' ')
    text = re.sub(r'\s+', ' ', text.strip())
    return text

# test normalize
# print(normalize("ÐŸÑ€Ð˜Ð²Ð•Ñ‚\nÐœÐ˜Ñ€\t"))
# print(normalize("Ñ‘Ð¶Ð¸Ðº, ÐÐ»ÐºÐ°",yo2e=True))
# print(normalize("Hello\r\nWorld"))
# print(normalize("  Ð´Ð²Ð¾Ð¹Ð½Ñ‹Ðµ   Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹  "))

def tokenize(text: str) -> list[str]:
    return re.findall(r'\w+(?:-\w+)*', text)

# test tokenize
# print(tokenize("Ð¿Ñ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€"))
# print(tokenize("hello,world!!!"))
# print(tokenize("Ð¿Ð¾-Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐ¼Ñƒ ÐºÑ€ÑƒÑ‚Ð¾"))
# print(tokenize("2025 Ð³Ð¾Ð´"))
# print(tokenize("emoji ðŸ˜€ Ð½Ðµ ÑÐ»Ð¾Ð²Ð¾"))

def count_freq(tokens: list[str]) -> dict[str, int]:
    ans = {}
    for token in tokens:
        if token not in ans:
            ans[token] = 1
        else:
            ans[token] += 1
    return ans

def top_n(freq: dict[str, int], n: int | None = None) -> list[tuple[str, int]]:
    sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    return sorted_items if n is None else sorted_items[:n]

#test count_freq and top_n
# print(count_freq(["a","b","a","c","b","a"]))
# print(top_n(count_freq(["a","b","a","c","b","a"]), 2))
# print(count_freq(["bb","aa","bb","aa","cc"]))
# print(top_n(count_freq(["bb","aa","bb","aa","cc"]), 2))